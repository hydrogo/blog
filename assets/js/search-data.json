{
  
    
        "post0": {
            "title": "Apps I use on Linux",
            "content": "I use Linux (Ubuntu LTS) as my primary operating system since 2015. Celebrating the 5th anniversary, I wish to share the list of applications (both standalone and web) I use on an everyday basis – for programming, writing, and chilling. I hope you will find some of them suitable for you to get more work done. Los! . Internet . Firefox – my default web-browser. Security, extensions, customization capabilities are the reasons to name it the must in available options. | Chrome – some applications (usually developed by government authorities) are still optimized directly for Chrome. It is nice to have Chrome at hand for these (rare) cases. | . Mails . Geary – for my personal email addresses, I always use corresponding native web-services (Gmail, Yandex), all work-related emails go to Geary. Minimalism and great shortcuts rule. | . GTD . TickTick – to-do list manager. Fast, multiplatform, and customizable. | Notion – a perfect tool to store all the stuff together in one place. | Google Keep – inbox for notes, which then go to the TickTick or Notion (or don’t). | . Messengers . Telegram – one love for messaging. | Slack – work-related chats. | . Writing . Google Docs – paper drafts, reviews, official documents. | Overleaf – powerful latex editor in your browser. The must for paper writing. | Notion – notes, lists, thoughts. | VS Code – for writing in the plain text of markdown. This post has been written in VS Code. | gedit – lightweight text editor. A great alternative to VS Code on old machines (e.g., for my 6 y.o. laptop). | LibreOffice – ugly, full of bugs, but sometimes useful for opening .docx. | . Programming . Anaconda – managing programming environments for Python. | Jupyter Notebook – interactive IDE for Python (other languages are also supported). Runs in your browser. | VS code – I use the VS Code when I need to write Python scripts or develop libraries. Many extensions for VS Code have been developed to make software development easier – linter, auto-completion, indentation, ssh-tunnelling, to name a few. | tmux – life-saving application to manage multiple terminals. | screen – when tmux is unavailable on a remote host. | nano – text editor that works in every terminal. | Google Colab – interactive cloud IDE for prototyping workflows that require GPU for feasible computation (e.g., deep neural networks). | vast.ai – service for renting remote hosts with GPU enabled. | . References . Zotero – saves all academic papers in one place. Useful tips and tricks on customization. | Mendeley – I migrated from Mendeley to Zotero because of two reasons: (1) Elsevier is an evil; (2) Mendeley extensions didn’t work correctly both for Firefox and Chrome. It could be an alternative if you don’t mind the reasons above. | . Drawing . Inkscape – for drawing vector graphics. | KolourPaint – Paint for Linux. | draw.io – for drawing diagrams (e.g., research workflows). | . Virtualization . VirtualBox – for having WindowsXP and MS Office 2003 at hand (not a joke). | . Music . Yandex.Music – works in Russia. | Spotify – works outside Russia. | . News . Feedly – RSS client that aggregates news from Habr, 5.38, and other blogs. | Tweetdeck – web-client for Tweeter from Tweeter. | Telegram – for reading channels (e.g., https://t.me/vsevstok). | . Utils . TeamViewer – the easiest way to connect to a remote server using a graphical interface. | Double Commander – two-panel file manager for oldies. | DeepL – translator powered by deep learning. A great alternative to Google.Translator. | Surfshark – VPN-client. | . Epilogue . I don’t have any plans to migrate from Linux back to Windows or to macOS. I am happy and satisfied with the tools I mentioned above – it is everything that I need to get my work done. .",
            "url": "https://hydrogo.github.io/blog/tips&tricks/2020/07/01/linux-apps.html",
            "relUrl": "/tips&tricks/2020/07/01/linux-apps.html",
            "date": " • Jul 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Скачиваем данные об уровнях воды из ЕСИМО",
            "content": "Что такое ЕСИМО? . ЕСИМО – единая государственная система информации об обстановке в Мировом океане. Несмотря на название, содержит в себе базы данных наблюдений за многими параметрами окружающей среды (посмотреть что есть). . Скачать данные вручную . Представление баз данных в ЕСИМО примерно одинаковое. Здесь и далее в качестве примера будем использовать оперативную базу данных измеренных уровней воды на гидропостах RU_RIHMI-WDC_1325_1. . Веб-интерфейс ЕСИМО для работы с базами данных монструозный, но дело свое делает – можно отсортировать, сделать выборку по дате. . На скриншоте показаны базовые элементы и какую кнопку нажать для скачивания. Я предпочитаю скачивать данные в csv – этот формат является более универсальным и с ним легче потом работать, чем с xls. . . . Даже если вы выберете один день и один пост, все равно скачаются все доступные на данный момент данные Недостатки такого варианта скачивания данных: . Все делается руками, | Так как данные доступны только за последние 7 дней, то заходить за оперативной информацией нужно регулярно. | . Код на python для автоматической загрузки данных . Чтобы не травмировать себя ежедневным общением с ЕСИМО нужно написать немного кода. Будем использовать стандартную библиотеку python, а также библиотеки request (для отправки запросов на сервер) и pandas (для обработки полученных данных). . # Импортируем необходимые библиотеки import io import datetime import requests import pandas as pd # Корневой адрес к которому мы будем делать запрос base_url = &#39;http://esimo.ru/dataview/getresourceexport&#39; # Идентификатор нашей базы данных db_id = &#39;RU_RIHMI-WDC_1325_1&#39; # Определяем даты # Будем скачивать данные за последнюю неделю # Сегодняшняя дата today = datetime.date.today() # Запрос устроен таким образом, что отсчет начинается с завтрашнего дня tomorrow = (today + datetime.timedelta(days=1)).strftime(&quot;%Y-%m-%d&quot;) week_back = (today - datetime.timedelta(days=6)).strftime(&quot;%Y-%m-%d&quot;) # Задаем параметры запроса params = {&#39;format&#39;: &#39;csv&#39;, &#39;resourceid&#39;: db_id, &#39;filter&#39;: f&quot;(((m4400 between &#39;{week_back}&#39; and &#39;{tomorrow}&#39;) or (CAST(m4400 as text) like &#39;%2099-12-31% &#39;)))&quot; } # Отправляем POST запрос на сервер response = requests.post(url=base_url, data=params) # Считываем пришедшие данные raw_data = response.content # Получаем данные в сыром виде, поэтому требуется # дополнительная обработка с помощью pandas data = pd.read_table(io.StringIO(raw_data.decode(&#39;utf-8&#39;)), header=0, sep=&#39;&quot;,&quot;&#39;, usecols=[0, 1, 2, 3, 4, 5, 7], names=[&quot;id&quot;, &quot;hydropost_name&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;timestamp&quot;, &quot;Level&quot;, &quot;Level_mean&quot;], engine=&#39;python&#39;) data[&quot;id&quot;] = data[&quot;id&quot;].apply(lambda x: str(x[1:])) data = data.drop_duplicates() # Сохраняем данные data.to_csv(f&quot;~/Downloads/esimo_{today.strftime(&#39;%Y%m%d&#39;)}.csv&quot;) . Попробовать в Google Colab. . Посмотрим на данные с гидропоста в Новокузнецке: . data[data[&quot;id&quot;]==&quot;10240&quot;] . . Теперь у нас в руках универсальный инструмент получения оперативных данных об измеренных уровнях воды. . Представленный фрагмент кода я использовал для создания системы краткосрочного прогнозирования уровня воды OpenLevels. Надеюсь, что и вам он пригодится. . Заключение . Несомненно, Росгидромету есть куда стремиться в улучшении доступа к результатам мониторинговых наблюдений на сети метеорологических станций и гидрологических постов. ЕСИМО в зубы не смотрят, но хотя бы посмотрите как обстоят дела в США: . Гидрологические данные, | Метеорологические данные. | . Отдельно отмечу оторванность нашей мониторинговой сети от глобальной сети обмена гидрологической информации WHOS, созданной в рамках Всемирной метеорологической организации. . Такая оторванность имеет тяжелые последствия. Например, в нашей недавней работе мы показали, что имея доступ к национальному архиву наблюдений за речным стоком, можно существенно улучшить качество регионального гидрологического реанализа. К сожалению, отсутствие этих данных в открытом доступе ограничивает эффективность моделей, на основе которых мы можем оценивать располагаемые водные ресурсы, а также возможную динамику их изменения в будущем. . Но эта уже совсем другая история. .",
            "url": "https://hydrogo.github.io/blog/tips&tricks/2020/06/26/get-esimo-data.html",
            "relUrl": "/tips&tricks/2020/06/26/get-esimo-data.html",
            "date": " • Jun 26, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am Georgy Ayzel . And this is how I work, think and live (actually not). . You are welcome to enjoy my posts about life and using open-source tools in hydrology. . Operational services . OpenForecast | OpenLevels | . Research interests . Hydrologic modelling | Calculations for ungauged basins | Short-term runoff forecasting | Machine and deep learning for hydrology | Land surface – Atmosphere interactions | Climate change assessment | Water resources under changing conditions | Quantitative precipitation nowcasting | . Current Research . Precipitation nowcasting using modern advances in image processing techniques and deep learning | Rainfall-runoff hydrological modelling using conceptual lumped models and state-of-art machine and deep learning techniques | . Publications . WoS-indexed publications can be viewed in my Orcid page | My profile on Google Scholar Google Scholar | . Education . Ph.D., 2014: Institute of Water Problems, Moscow, Russia | M.S., 2011: Department of Hydrology, Geographical Faculty, Lomonosov Moscow State University, Russia | . Motivation . Open Science: open data, free software, reproducible research | Memento Mori | .",
          "url": "https://hydrogo.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}